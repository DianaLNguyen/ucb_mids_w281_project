{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048c5e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/diana/anaconda3/lib/python3.9/site-packages (3.5.2)\n",
      "Requirement already satisfied: scikit-image in /home/diana/anaconda3/lib/python3.9/site-packages (0.19.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/diana/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/diana/.local/lib/python3.9/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/diana/anaconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/diana/anaconda3/lib/python3.9/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/diana/anaconda3/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/diana/anaconda3/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/diana/anaconda3/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/diana/.local/lib/python3.9/site-packages (from matplotlib) (1.24.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/diana/anaconda3/lib/python3.9/site-packages (from scikit-image) (2.8.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/diana/anaconda3/lib/python3.9/site-packages (from scikit-image) (2021.7.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/diana/anaconda3/lib/python3.9/site-packages (from scikit-image) (2.19.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/diana/anaconda3/lib/python3.9/site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/diana/anaconda3/lib/python3.9/site-packages (from scikit-image) (1.9.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/diana/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 17:41:09.366839: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-27 17:41:09.595485: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/diana/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-07-27 17:41:09.595497: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-27 17:41:10.352821: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/diana/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-07-27 17:41:10.352990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/diana/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-07-27 17:41:10.352996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib scikit-image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import exposure\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.measure import regionprops, find_contours\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cda539c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>suit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DatasetPreProcessed/train/ace of clubs/001.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DatasetPreProcessed/train/ace of clubs/002.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DatasetPreProcessed/train/ace of clubs/003.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DatasetPreProcessed/train/ace of clubs/004.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DatasetPreProcessed/train/ace of clubs/005.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        filepaths   suit\n",
       "0  DatasetPreProcessed/train/ace of clubs/001.jpg  clubs\n",
       "1  DatasetPreProcessed/train/ace of clubs/002.jpg  clubs\n",
       "2  DatasetPreProcessed/train/ace of clubs/003.jpg  clubs\n",
       "3  DatasetPreProcessed/train/ace of clubs/004.jpg  clubs\n",
       "4  DatasetPreProcessed/train/ace of clubs/005.jpg  clubs"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the image paths and labels from the DataFrame\n",
    "df = pd.read_csv('Dataset/cards.csv')\n",
    "\n",
    "# For column names that contain space, replace the space with an underscore\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "\n",
    "# Add suits column\n",
    "df['suit'] = df['labels'].str.split().str[-1]\n",
    "\n",
    "# Remove rows with jokers\n",
    "df = df[~df['suit'].str.contains('joker', case=False)]\n",
    "\n",
    "# Remove unwanted columns\n",
    "df = df.drop(columns = ['data_set'])\n",
    "df = df.drop(columns = ['class_index'])\n",
    "df = df.drop(columns = ['labels'])\n",
    "df = df.drop(columns = ['card_type'])\n",
    "\n",
    "# Add folder name to the filepath\n",
    "df['filepaths'] = df['filepaths'].apply(lambda x: 'DatasetPreProcessed/' + x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fabeb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set - Class Distribution:\n",
      "spades      0.269171\n",
      "hearts      0.246010\n",
      "diamonds    0.243675\n",
      "clubs       0.241144\n",
      "Name: suit, dtype: float64\n",
      "Validation Set - Class Distribution:\n",
      "spades      0.269261\n",
      "hearts      0.245914\n",
      "diamonds    0.243580\n",
      "clubs       0.241245\n",
      "Name: suit, dtype: float64\n",
      "Test Set - Class Distribution:\n",
      "spades      0.268991\n",
      "hearts      0.245953\n",
      "diamonds    0.244085\n",
      "clubs       0.240971\n",
      "Name: suit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split dataframe into train and test sets, stratified by the 'suit' column\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['suit'], random_state=42)\n",
    "\n",
    "# Split train set into train and validation sets, stratified by the 'suit' column\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['suit'], random_state=42)\n",
    "\n",
    "# Check class distribution in the train, validation, and test sets\n",
    "train_class_distribution = train_df['suit'].value_counts(normalize=True)\n",
    "val_class_distribution = val_df['suit'].value_counts(normalize=True)\n",
    "test_class_distribution = test_df['suit'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Train Set - Class Distribution:\")\n",
    "print(train_class_distribution)\n",
    "\n",
    "print(\"Validation Set - Class Distribution:\")\n",
    "print(val_class_distribution)\n",
    "\n",
    "print(\"Test Set - Class Distribution:\")\n",
    "print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b360a9b",
   "metadata": {},
   "source": [
    "## Augment Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd1b9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5138 validated image filenames belonging to 4 classes.\n",
      "Found 1285 validated image filenames belonging to 4 classes.\n",
      "Found 1606 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize data generator class\n",
    "\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale = 1/255.0,\n",
    "    rotation_range= 45,\n",
    "    zoom_range= 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range= 0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale = 1/255.0)\n",
    "\n",
    "# Create data generators for train, validation, and test\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "valid_generator = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = val_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f021434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the images\n",
    "def load_and_preprocess_image(filepath):\n",
    "    image = cv2.imread(filepath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    return image\n",
    "\n",
    "def convert_to_hsv(images):\n",
    "    hsv_images = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2HSV) for img in images])\n",
    "    return hsv_images\n",
    "\n",
    "# # Convert to image to grayscale\n",
    "# def convert_to_grayscale(images):\n",
    "#     gray_images = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in images])\n",
    "#     gray_images = gray_images.astype(np.uint8)\n",
    "#     return gray_images\n",
    "\n",
    "# Extract HOG feature vectors\n",
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for img in images:\n",
    "        hog_features_channel = []\n",
    "        for channel in range(img.shape[-1]):  # Iterate over each channel in the image\n",
    "            hog_feature = hog(img[..., channel], pixels_per_cell=(8, 8), cells_per_block=(2, 2))#, orientations=4)\n",
    "            hog_features_channel.append(hog_feature)\n",
    "        hog_features.append(np.hstack(hog_features_channel))\n",
    "    return np.array(hog_features)\n",
    "\n",
    "\n",
    "\n",
    "def combine_hog_with_color(hog_features, color_features):\n",
    "    return np.hstack((hog_features, color_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c7b2b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the generators and extract HOG features\n",
    "train_images = np.array([load_and_preprocess_image(train_generator.filepaths[i]) for i in range(len(train_generator.filenames))])\n",
    "valid_images = np.array([load_and_preprocess_image(valid_generator.filepaths[j]) for j in range(len(valid_generator.filenames))])\n",
    "test_images = np.array([load_and_preprocess_image(test_generator.filepaths[k]) for k in range(len(test_generator.filenames))])\n",
    "\n",
    "# Convert images to HSV\n",
    "train_hsv_images = convert_to_hsv(train_images)\n",
    "valid_hsv_images = convert_to_hsv(valid_images)\n",
    "test_hsv_images = convert_to_hsv(test_images)\n",
    "\n",
    "# # Extract HOG feature vectors\n",
    "# train_hog_features = extract_hog_features(train_hsv_images)\n",
    "# valid_hog_features = extract_hog_features(valid_hsv_images)\n",
    "# test_hog_features = extract_hog_features(test_hsv_images)\n",
    "\n",
    "# Combine HOG features with color features\n",
    "train_color_features = train_hsv_images.reshape(train_hsv_images.shape[0], -1)\n",
    "valid_color_features = valid_hsv_images.reshape(valid_hsv_images.shape[0], -1)\n",
    "test_color_features = test_hsv_images.reshape(test_hsv_images.shape[0], -1)\n",
    "\n",
    "train_features = combine_hog_with_color(extract_hog_features(train_hsv_images), train_color_features)\n",
    "valid_features = combine_hog_with_color(extract_hog_features(valid_hsv_images), valid_color_features)\n",
    "test_features = combine_hog_with_color(extract_hog_features(test_hsv_images), test_color_features)\n",
    "\n",
    "# Convert labels to arrays and one-hot encode\n",
    "train_labels = to_categorical(train_generator.labels, num_classes=4)\n",
    "valid_labels = to_categorical(valid_generator.labels, num_classes=4)\n",
    "test_labels = to_categorical(test_generator.labels, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9836ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 17:47:27.572062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/diana/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-07-27 17:47:27.572317: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-27 17:47:27.572352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (diana-MS-7D19): /proc/driver/nvidia/version does not exist\n",
      "2023-07-27 17:47:27.573024: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# SVM using the train HOG features\n",
    "num_classes = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_features.shape[1],)))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ad0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=20,\n",
    "                    validation_data=(valid_features, valid_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "valid_predictions_probs = model.predict(valid_features)\n",
    "valid_predictions = np.argmax(valid_predictions_probs, axis=1)\n",
    "\n",
    "# Calculate validation accuracy\n",
    "valid_accuracy = accuracy_score(valid_generator.labels, valid_predictions)\n",
    "print(\"Validation Accuracy:\", valid_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_probs = model.predict(test_features)\n",
    "test_predictions = np.argmax(test_predictions_probs, axis=1)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = accuracy_score(test_generator.labels, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f750b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class names from the generator (assuming it has the 'class_indices' attribute)\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Calculate classification report for validation set\n",
    "valid_report = classification_report(valid_generator.labels, valid_predictions, target_names=class_names)\n",
    "print(\"Validation Classification Report:\\n\", valid_report)\n",
    "\n",
    "# Calculate classification report for test set\n",
    "test_report = classification_report(test_generator.labels, test_predictions, target_names=class_names)\n",
    "print(\"Test Classification Report:\\n\", test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab701bf",
   "metadata": {},
   "source": [
    "## Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_filepaths = [\n",
    "    'Dataset/train/three of diamonds/006.jpg',\n",
    "    'Dataset/train/three of diamonds/002.jpg',\n",
    "    'Dataset/train/ace of diamonds/064.jpg',\n",
    "    'Dataset/train/ace of diamonds/063.jpg',\n",
    "    'Dataset/train/nine of clubs/024.jpg',\n",
    "    'Dataset/train/nine of clubs/070.jpg',\n",
    "    'Dataset/train/ace of clubs/066.jpg',\n",
    "    'Dataset/train/ace of clubs/047.jpg',\n",
    "    'Dataset/train/queen of hearts/005.jpg',\n",
    "    'Dataset/train/three of hearts/056.jpg',\n",
    "    'Dataset/train/two of hearts/033.jpg',\n",
    "    'Dataset/train/eight of hearts/100.jpg',\n",
    "    'Dataset/train/king of spades/005.jpg',\n",
    "    'Dataset/train/jack of spades/014.jpg',\n",
    "    'Dataset/train/jack of spades/055.jpg',\n",
    "    'Dataset/train/seven of spades/055.jpg'\n",
    "]\n",
    "\n",
    "# Load and preprocess the sample images\n",
    "sample_images = np.array([load_and_preprocess_image(filepath) for filepath in sample_filepaths])\n",
    "\n",
    "# Convert the images to grayscale\n",
    "sample_gray_images = convert_to_grayscale(sample_images)\n",
    "\n",
    "# Extract HOG features for the sample images\n",
    "sample_hog_features = extract_hog_features(sample_gray_images)\n",
    "\n",
    "# Calculate the number of images\n",
    "num_images = len(sample_images)\n",
    "\n",
    "for i in range(num_images):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    ax[0].imshow(sample_images[i], cmap='gray')\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    hog_image = hog(sample_gray_images[i], pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)[1]\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "    ax[1].imshow(hog_image_rescaled, cmap='gray')\n",
    "    ax[1].set_title('HOG Features')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4833d77f",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64786e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on the HOG features.\n",
    "pca = PCA()\n",
    "hog_features_pca = pca.fit_transform(train_hog_features)\n",
    "\n",
    "# Cumulative explained variance.\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Determine the number of principal components to plot with increments of 100.\n",
    "num_components = hog_features_pca.shape[1]\n",
    "components_range = np.arange(1, num_components + 1, 100)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(components_range, cumulative_explained_variance[components_range - 1], marker='o')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA - Cumulative Explained Variance')\n",
    "plt.xticks(components_range, fontsize=6)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
