{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca5ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 22:46:23.288646: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-24 22:46:23.313668: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import exposure\n",
    "from skimage import color\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.measure import regionprops, find_contours\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed8551e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>suit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/train/ace of clubs/001.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/train/ace of clubs/002.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/train/ace of clubs/003.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/train/ace of clubs/004.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/train/ace of clubs/005.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filepaths   suit\n",
       "0  Dataset/train/ace of clubs/001.jpg  clubs\n",
       "1  Dataset/train/ace of clubs/002.jpg  clubs\n",
       "2  Dataset/train/ace of clubs/003.jpg  clubs\n",
       "3  Dataset/train/ace of clubs/004.jpg  clubs\n",
       "4  Dataset/train/ace of clubs/005.jpg  clubs"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the image paths and labels from the DataFrame\n",
    "df = pd.read_csv('Dataset/cards.csv')\n",
    "\n",
    "# For column names that contain space, replace the space with an underscore\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "\n",
    "# Add suits column\n",
    "df['suit'] = df['labels'].str.split().str[-1]\n",
    "\n",
    "# Remove rows with jokers\n",
    "df = df[~df['suit'].str.contains('joker', case=False)]\n",
    "\n",
    "# Remove unwanted columns\n",
    "df = df.drop(columns = ['data_set'])\n",
    "df = df.drop(columns = ['class_index'])\n",
    "df = df.drop(columns = ['labels'])\n",
    "df = df.drop(columns = ['card_type'])\n",
    "\n",
    "# Add folder name to the filepath\n",
    "df['filepaths'] = df['filepaths'].apply(lambda x: 'Dataset/' + x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2053537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set - Class Distribution:\n",
      "spades      0.269171\n",
      "hearts      0.246010\n",
      "diamonds    0.243675\n",
      "clubs       0.241144\n",
      "Name: suit, dtype: float64\n",
      "Validation Set - Class Distribution:\n",
      "spades      0.269261\n",
      "hearts      0.245914\n",
      "diamonds    0.243580\n",
      "clubs       0.241245\n",
      "Name: suit, dtype: float64\n",
      "Test Set - Class Distribution:\n",
      "spades      0.268991\n",
      "hearts      0.245953\n",
      "diamonds    0.244085\n",
      "clubs       0.240971\n",
      "Name: suit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split dataframe into train and test sets, stratified by the 'suit' column\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['suit'], random_state=42)\n",
    "\n",
    "# Split train set into train and validation sets, stratified by the 'suit' column\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['suit'], random_state=42)\n",
    "\n",
    "# Check class distribution in the train, validation, and test sets\n",
    "train_class_distribution = train_df['suit'].value_counts(normalize=True)\n",
    "val_class_distribution = val_df['suit'].value_counts(normalize=True)\n",
    "test_class_distribution = test_df['suit'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Train Set - Class Distribution:\")\n",
    "print(train_class_distribution)\n",
    "\n",
    "print(\"Validation Set - Class Distribution:\")\n",
    "print(val_class_distribution)\n",
    "\n",
    "print(\"Test Set - Class Distribution:\")\n",
    "print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad52bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5138 validated image filenames belonging to 4 classes.\n",
      "Found 1285 validated image filenames belonging to 4 classes.\n",
      "Found 1606 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize data generator class\n",
    "\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale = 1/255.0,\n",
    "    rotation_range= 45,\n",
    "    zoom_range= 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range= 0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale = 1/255.0)\n",
    "\n",
    "# Create data generators for train, validation, and test\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "valid_generator = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = val_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "973ed158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(image):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Compute HOG features\n",
    "    features, _ = hog(gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_hog_features_from_generator(data_generator):\n",
    "    hog_features = []\n",
    "    labels = []\n",
    "\n",
    "    for images, batch_labels in data_generator:\n",
    "        for image, label in zip(images, batch_labels):\n",
    "            hog_feature = extract_hog_features(image)\n",
    "            hog_features.append(hog_feature)\n",
    "            labels.append(np.argmax(label))\n",
    "\n",
    "        if len(hog_features) >= data_generator.n:\n",
    "            break\n",
    "\n",
    "    return np.array(hog_features), np.array(labels)\n",
    "\n",
    "def train_logistic_regression(train_data, train_labels):\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(train_data, train_labels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a086f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HOG features from the training set\n",
    "train_hog_features, train_labels = extract_hog_features_from_generator(train_generator)\n",
    "\n",
    "# Extract HOG features from the validation set\n",
    "valid_hog_features, valid_labels = extract_hog_features_from_generator(valid_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c53d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression classifier\n",
    "log_reg_model = train_logistic_regression(train_hog_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6da978bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2559153175591532\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.35      0.30       387\n",
      "           1       0.24      0.27      0.25       392\n",
      "           2       0.26      0.20      0.23       395\n",
      "           3       0.26      0.22      0.24       432\n",
      "\n",
      "    accuracy                           0.26      1606\n",
      "   macro avg       0.26      0.26      0.25      1606\n",
      "weighted avg       0.26      0.26      0.25      1606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract HOG features from the test set\n",
    "test_hog_features, test_labels = extract_hog_features_from_generator(test_generator)\n",
    "\n",
    "# Make predictions using the trained logistic regression model\n",
    "predictions = log_reg_model.predict(test_hog_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a5001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b404f82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6090dae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067c953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55cc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c36e4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d27ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170c015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
