{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca5ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 21:45:54.425894: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-24 21:45:54.449039: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import exposure\n",
    "from skimage import color\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.measure import regionprops, find_contours\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed8551e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>suit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/train/ace of clubs/001.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/train/ace of clubs/002.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/train/ace of clubs/003.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/train/ace of clubs/004.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/train/ace of clubs/005.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filepaths   suit\n",
       "0  Dataset/train/ace of clubs/001.jpg  clubs\n",
       "1  Dataset/train/ace of clubs/002.jpg  clubs\n",
       "2  Dataset/train/ace of clubs/003.jpg  clubs\n",
       "3  Dataset/train/ace of clubs/004.jpg  clubs\n",
       "4  Dataset/train/ace of clubs/005.jpg  clubs"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the image paths and labels from the DataFrame\n",
    "df = pd.read_csv('Dataset/cards.csv')\n",
    "\n",
    "# For column names that contain space, replace the space with an underscore\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "\n",
    "# Add suits column\n",
    "df['suit'] = df['labels'].str.split().str[-1]\n",
    "\n",
    "# Remove rows with jokers\n",
    "df = df[~df['suit'].str.contains('joker', case=False)]\n",
    "\n",
    "# Remove unwanted columns\n",
    "df = df.drop(columns = ['data_set'])\n",
    "df = df.drop(columns = ['class_index'])\n",
    "df = df.drop(columns = ['labels'])\n",
    "df = df.drop(columns = ['card_type'])\n",
    "\n",
    "# Add folder name to the filepath\n",
    "df['filepaths'] = df['filepaths'].apply(lambda x: 'Dataset/' + x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2053537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set - Class Distribution:\n",
      "spades      0.269171\n",
      "hearts      0.246010\n",
      "diamonds    0.243675\n",
      "clubs       0.241144\n",
      "Name: suit, dtype: float64\n",
      "Validation Set - Class Distribution:\n",
      "spades      0.269261\n",
      "hearts      0.245914\n",
      "diamonds    0.243580\n",
      "clubs       0.241245\n",
      "Name: suit, dtype: float64\n",
      "Test Set - Class Distribution:\n",
      "spades      0.268991\n",
      "hearts      0.245953\n",
      "diamonds    0.244085\n",
      "clubs       0.240971\n",
      "Name: suit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split dataframe into train and test sets, stratified by the 'suit' column\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['suit'], random_state=42)\n",
    "\n",
    "# Split train set into train and validation sets, stratified by the 'suit' column\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['suit'], random_state=42)\n",
    "\n",
    "# Check class distribution in the train, validation, and test sets\n",
    "train_class_distribution = train_df['suit'].value_counts(normalize=True)\n",
    "val_class_distribution = val_df['suit'].value_counts(normalize=True)\n",
    "test_class_distribution = test_df['suit'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Train Set - Class Distribution:\")\n",
    "print(train_class_distribution)\n",
    "\n",
    "print(\"Validation Set - Class Distribution:\")\n",
    "print(val_class_distribution)\n",
    "\n",
    "print(\"Test Set - Class Distribution:\")\n",
    "print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad52bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5138 validated image filenames belonging to 4 classes.\n",
      "Found 1285 validated image filenames belonging to 4 classes.\n",
      "Found 1606 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize data generator class\n",
    "\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale = 1/255.0,\n",
    "    rotation_range= 45,\n",
    "    zoom_range= 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range= 0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale = 1/255.0)\n",
    "\n",
    "# Create data generators for train, validation, and test\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "valid_generator = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = val_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4959c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    # Convert the image to grayscale\n",
    "    grayscale_image = rgb2gray(image)\n",
    "\n",
    "    # Resize the image to a consistent size (e.g., (224, 224))\n",
    "    resized_image = resize(grayscale_image, (224, 224))\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "# Function to compute HOG features for a single preprocessed image\n",
    "def compute_hog_features(image):\n",
    "    # Compute the HOG features for the image\n",
    "    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n",
    "    return fd\n",
    "\n",
    "# Function to compute HOG features for a batch of images\n",
    "def compute_batch_hog_features(image_generator):\n",
    "    hog_features = []\n",
    "    for _ in range(len(image_generator)):\n",
    "        image_batch, _ = next(image_generator)  # Get a batch of images (ignore the labels)\n",
    "        for image in image_batch:\n",
    "            preprocessed_image = preprocess_image(image)\n",
    "            hog_features.append(compute_hog_features(preprocessed_image))\n",
    "    return np.array(hog_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7191693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute HOG features for train, validation, and test sets\n",
    "train_hog_features = compute_batch_hog_features(train_generator)\n",
    "valid_hog_features = compute_batch_hog_features(valid_generator)\n",
    "test_hog_features = compute_batch_hog_features(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "614d2ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a82524d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the train HOG features and corresponding labels\n",
    "model.fit(train_hog_features, train_generator.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e5a3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the validation set\n",
    "valid_predictions = model.predict(valid_hog_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0631731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the predicted labels to get the final class predictions\n",
    "valid_predictions = np.round(valid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34103502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predictions to integers (required by some evaluation metrics)\n",
    "valid_predictions = valid_predictions.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3246f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2602739726027397\n",
      "Precision: 0.25972345473214475\n",
      "Recall: 0.2602739726027397\n",
      "F1-score: 0.22604073251263854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Convert the test labels to integers (required by some evaluation metrics)\n",
    "test_labels = test_generator.labels\n",
    "\n",
    "# Predict the labels for the test set\n",
    "test_predictions = model.predict(test_hog_features)\n",
    "\n",
    "# Round the predicted labels to get the final class predictions\n",
    "test_predictions = np.round(test_predictions)\n",
    "\n",
    "# Convert the predictions to integers (required by some evaluation metrics)\n",
    "test_predictions = test_predictions.astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf32cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3ebfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae34db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a14379b7",
   "metadata": {},
   "source": [
    "# Least Squares Classiciation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e2b030",
   "metadata": {},
   "source": [
    "#### Extract HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12942287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "# Function to compute HOG features for a single image\n",
    "def compute_hog_features(image):\n",
    "    # Compute the HOG features for the image\n",
    "    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n",
    "\n",
    "    return fd\n",
    "\n",
    "# Function to compute HOG features for a batch of images\n",
    "def compute_batch_hog_features(image_batch):\n",
    "    hog_features = []\n",
    "    for image in image_batch:\n",
    "        hog_features.append(compute_hog_features(image))\n",
    "    return np.array(hog_features)\n",
    "\n",
    "# Compute HOG features for train, validation, and test sets\n",
    "train_hog_features = compute_batch_hog_features(train_generator)\n",
    "valid_hog_features = compute_batch_hog_features(valid_generator)\n",
    "test_hog_features = compute_batch_hog_features(test_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcff12",
   "metadata": {},
   "source": [
    "#### Perform Least Squares Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the train HOG features and corresponding labels\n",
    "model.fit(train_hog_features, train_generator.labels)\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "valid_predictions = model.predict(valid_hog_features)\n",
    "\n",
    "# Round the predicted labels to get the final class predictions\n",
    "valid_predictions = np.round(valid_predictions)\n",
    "\n",
    "# Convert the predictions to integers (required by some evaluation metrics)\n",
    "valid_predictions = valid_predictions.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4a6cd1",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b66f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Convert the test labels to integers (required by some evaluation metrics)\n",
    "test_labels = test_generator.labels\n",
    "\n",
    "# Predict the labels for the test set\n",
    "test_predictions = model.predict(test_hog_features)\n",
    "\n",
    "# Round the predicted labels to get the final class predictions\n",
    "test_predictions = np.round(test_predictions)\n",
    "\n",
    "# Convert the predictions to integers (required by some evaluation metrics)\n",
    "test_predictions = test_predictions.astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11470d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
