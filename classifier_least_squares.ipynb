{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca5ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import exposure\n",
    "from skimage import color\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.measure import regionprops, find_contours\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image paths and labels from the DataFrame\n",
    "df = pd.read_csv('Dataset/cards.csv')\n",
    "\n",
    "# For column names that contain space, replace the space with an underscore\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "\n",
    "# Add suits column\n",
    "df['suit'] = df['labels'].str.split().str[-1]\n",
    "\n",
    "# Remove rows with jokers\n",
    "df = df[~df['suit'].str.contains('joker', case=False)]\n",
    "\n",
    "# Remove unwanted columns\n",
    "df = df.drop(columns = ['data_set'])\n",
    "df = df.drop(columns = ['class_index'])\n",
    "df = df.drop(columns = ['labels'])\n",
    "df = df.drop(columns = ['card_type'])\n",
    "\n",
    "# Add folder name to the filepath\n",
    "df['filepaths'] = df['filepaths'].apply(lambda x: 'Dataset/' + x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2053537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe into train and test sets, stratified by the 'suit' column\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['suit'], random_state=42)\n",
    "\n",
    "# Split train set into train and validation sets, stratified by the 'suit' column\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['suit'], random_state=42)\n",
    "\n",
    "# Check class distribution in the train, validation, and test sets\n",
    "train_class_distribution = train_df['suit'].value_counts(normalize=True)\n",
    "val_class_distribution = val_df['suit'].value_counts(normalize=True)\n",
    "test_class_distribution = test_df['suit'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Train Set - Class Distribution:\")\n",
    "print(train_class_distribution)\n",
    "\n",
    "print(\"Validation Set - Class Distribution:\")\n",
    "print(val_class_distribution)\n",
    "\n",
    "print(\"Test Set - Class Distribution:\")\n",
    "print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad52bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data generator class\n",
    "\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale = 1/255.0,\n",
    "    rotation_range= 45,\n",
    "    zoom_range= 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range= 0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale = 1/255.0)\n",
    "\n",
    "# Create data generators for train, validation, and test\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "valid_generator = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = val_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a073e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "\n",
    "def compute_hog_features(image):\n",
    "    # Convert the image to grayscale if it's in color\n",
    "    if image.shape[-1] == 3:\n",
    "        image = rgb2gray(image)\n",
    "\n",
    "    # Compute the HOG features for the image\n",
    "    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n",
    "\n",
    "    return fd\n",
    "\n",
    "# Function to compute HOG features for a batch of images\n",
    "def compute_batch_hog_features(image_batch):\n",
    "    hog_features = []\n",
    "    for images, _ in image_batch:  # Extract image data and ignore the labels\n",
    "        for image in images:\n",
    "            hog_features.append(compute_hog_features(image))\n",
    "    return np.array(hog_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e223278",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute HOG features for train, validation, and test sets\n",
    "train_hog_features = compute_batch_hog_features(train_generator)\n",
    "valid_hog_features = compute_batch_hog_features(valid_generator)\n",
    "test_hog_features = compute_batch_hog_features(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a0e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057524f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9e723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4dd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81459819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9a687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae5dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aeebb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d480d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9568a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_array):\n",
    "    # Convert the image to grayscale if it's in color\n",
    "    if image_array.shape[-1] == 3:\n",
    "        image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    adaptive_thresh = threshold_local(image_array, block_size=11, method='gaussian', offset=2)\n",
    "\n",
    "    return (image_array > adaptive_thresh).astype(np.uint8) * 255\n",
    "\n",
    "def detect_suit_regions(image_path):\n",
    "    image = load_img(image_path)\n",
    "    image_array = img_to_array(image)\n",
    "\n",
    "    # convert image to grayscale.\n",
    "    image_array = preprocess_image(image_array)\n",
    "\n",
    "    # Convert the image to binary using Otsu's thresholding.\n",
    "    # Otsu's thresholding divides the pixels of the image into two classes: foreground and background.\n",
    "    # Helps isolate region of interest for feature extraction\n",
    "    binary_image = image_array > threshold_otsu(image_array)\n",
    "\n",
    "    # Erode the binary image to enhance the suits.\n",
    "    # Eroding reduces the size of the white regions of the foreground.\n",
    "    eroded_image = binary_erosion(binary_image)\n",
    "\n",
    "    # Find contours, the outlines that have the same intensity, in the eroded image.\n",
    "    contours = find_contours(eroded_image, 0.8)\n",
    "\n",
    "    # Check if any contours are detected.\n",
    "    # If not, then return None\n",
    "    if not contours:\n",
    "        print(f\"No suit regions detected for {image_path}\")\n",
    "        return None\n",
    "\n",
    "    # Find the largest contour, assuming it corresponds to the suit region.\n",
    "    suit_contour = max(contours, key=lambda x: x[:, 0].size)\n",
    "\n",
    "    # Get the bounding box of the suit contour.\n",
    "    minr, minc = np.min(suit_contour, axis=0).astype(int)\n",
    "    maxr, maxc = np.max(suit_contour, axis=0).astype(int)\n",
    "\n",
    "    # Check if the bounding box has valid dimensions (not too small).\n",
    "    min_size = 10\n",
    "    if maxr - minr < min_size or maxc - minc < min_size:\n",
    "        print(f\"Suit region too small for HOG features in {image_path}\")\n",
    "        return None\n",
    "\n",
    "    # Crop the suit region from the original image.\n",
    "    suit_image = image_array[minr:maxr, minc:maxc]\n",
    "\n",
    "    # Calculate HOG features for the suit region.\n",
    "    fd, hog_image = hog(suit_image, orientations=8, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "\n",
    "    # Normalize the HOG features.\n",
    "    hog_features = exposure.rescale_intensity(fd, in_range=(0, 10))\n",
    "\n",
    "    return hog_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f226c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute HOG features for a batch of images\n",
    "def compute_train_hog_features(image_batch):\n",
    "    hog_features_list_train = []\n",
    "    for i in range(len(train_generator.filenames)):\n",
    "        image_path = train_generator.filepaths[i]\n",
    "        hog_features = detect_suit_regions(image_path)\n",
    "        if hog_features is not None:\n",
    "            # Check if the shape of the HOG features is consistent.\n",
    "            if len(hog_features) == 768:  # Update this value to match the expected feature size.\n",
    "                hog_features_list_train.append(hog_features)\n",
    "\n",
    "    # Convert the list of HOG feature arrays into a 2D array (samples x features).\n",
    "    hog_features_array_train = np.vstack(hog_features_list_train)\n",
    "    \n",
    "    return hog_features_array_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b85680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute HOG features for a batch of images\n",
    "def compute_valid_hog_features(image_batch):\n",
    "    hog_features_list_valid = []\n",
    "    for idx_valid in range(len(valid_generator.filenames)):\n",
    "        image_path_valid = valid_generator.filepaths[idx_valid]\n",
    "        hog_features_valid = detect_suit_regions(image_path_valid)\n",
    "        if hog_features_valid is not None:\n",
    "            # Check if the shape of the HOG features is consistent.\n",
    "            if len(hog_features_valid) == 768:  # Update this value to match the expected feature size.\n",
    "                hog_features_list_valid.append(hog_features_valid)\n",
    "\n",
    "    # Convert the list of HOG feature arrays into a 2D array (samples x features).\n",
    "    hog_features_array_valid = np.vstack(hog_features_list_valid)\n",
    "    \n",
    "    return hog_features_array_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1629e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute HOG features for a batch of images\n",
    "def compute_test_hog_features(image_batch):\n",
    "    hog_features_list_test = []\n",
    "    for idx_test in range(len(test_generator.filenames)):\n",
    "        image_path_test = test_generator.filepaths[idx_test]\n",
    "        hog_features_test = detect_suit_regions(image_path_test)\n",
    "        if hog_features_test is not None:\n",
    "            # Check if the shape of the HOG features is consistent.\n",
    "            if len(hog_features_test) == 768:  # Update this value to match the expected feature size.\n",
    "                hog_features_list_test.append(hog_features_test)\n",
    "\n",
    "    # Convert the list of HOG feature arrays into a 2D array (samples x features).\n",
    "    hog_features_array_test = np.vstack(hog_features_list_test)\n",
    "    \n",
    "    return hog_features_array_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c24d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute HOG features for train, validation, and test sets\n",
    "train_hog_features = compute_train_hog_features(train_generator)\n",
    "valid_hog_features = compute_valid_hog_features(valid_generator)\n",
    "test_hog_features = compute_test_hog_features(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b2547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b495b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361fb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cfa35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d4869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b898ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99b694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a14379b7",
   "metadata": {},
   "source": [
    "# Least Squares Classiciation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e2b030",
   "metadata": {},
   "source": [
    "#### Extract HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12942287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "# Function to compute HOG features for a single image\n",
    "def compute_hog_features(image):\n",
    "    # Compute the HOG features for the image\n",
    "    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n",
    "\n",
    "    return fd\n",
    "\n",
    "# Function to compute HOG features for a batch of images\n",
    "def compute_batch_hog_features(image_batch):\n",
    "    hog_features = []\n",
    "    for image in image_batch:\n",
    "        hog_features.append(compute_hog_features(image))\n",
    "    return np.array(hog_features)\n",
    "\n",
    "# Compute HOG features for train, validation, and test sets\n",
    "train_hog_features = compute_batch_hog_features(train_generator)\n",
    "valid_hog_features = compute_batch_hog_features(valid_generator)\n",
    "test_hog_features = compute_batch_hog_features(test_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcff12",
   "metadata": {},
   "source": [
    "#### Perform Least Squares Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the train HOG features and corresponding labels\n",
    "model.fit(train_hog_features, train_generator.labels)\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "valid_predictions = model.predict(valid_hog_features)\n",
    "\n",
    "# Round the predicted labels to get the final class predictions\n",
    "valid_predictions = np.round(valid_predictions)\n",
    "\n",
    "# Convert the predictions to integers (required by some evaluation metrics)\n",
    "valid_predictions = valid_predictions.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4a6cd1",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b66f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Convert the test labels to integers (required by some evaluation metrics)\n",
    "test_labels = test_generator.labels\n",
    "\n",
    "# Predict the labels for the test set\n",
    "test_predictions = model.predict(test_hog_features)\n",
    "\n",
    "# Round the predicted labels to get the final class predictions\n",
    "test_predictions = np.round(test_predictions)\n",
    "\n",
    "# Convert the predictions to integers (required by some evaluation metrics)\n",
    "test_predictions = test_predictions.astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11470d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f35d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f221e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a43b3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Function to create bounding boxes around suits\n",
    "def create_bounding_boxes(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding to create binary image\n",
    "    _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours of suits\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    bounding_boxes = []\n",
    "    for contour in contours:\n",
    "        # Find the bounding box for each contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        bounding_boxes.append((x, y, x + w, y + h))  # Store the bounding box coordinates as (x_min, y_min, x_max, y_max)\n",
    "\n",
    "    return bounding_boxes\n",
    "\n",
    "# Function to compute HOG features for a single bounding box\n",
    "def compute_hog_features(image):\n",
    "    # Compute the HOG features for the bounding box image\n",
    "    fd, _ = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n",
    "    return fd\n",
    "\n",
    "# Function to compute HOG features for a batch of bounding boxes\n",
    "def compute_batch_hog_features(image_batch):\n",
    "    hog_features = []\n",
    "    for image in image_batch:\n",
    "        hog_features_calc = compute_hog_features(image)\n",
    "        hog_features.append(hog_features_calc)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "# Create bounding boxes for train, validation, and test sets\n",
    "train_bounding_boxes = [create_bounding_boxes(image_path) for image_path in train_df['filepaths']]\n",
    "valid_bounding_boxes = [create_bounding_boxes(image_path) for image_path in val_df['filepaths']]\n",
    "test_bounding_boxes = [create_bounding_boxes(image_path) for image_path in test_df['filepaths']]\n",
    "\n",
    "# Compute HOG features for train, validation, and test sets\n",
    "train_hog_features = compute_batch_hog_features(train_bounding_boxes)\n",
    "valid_hog_features = compute_batch_hog_features(valid_bounding_boxes)\n",
    "test_hog_features = compute_batch_hog_features(test_bounding_boxes)\n",
    "\n",
    "# Prepare feature matrices for train, validation, and test sets\n",
    "X_train = train_hog_features\n",
    "X_valid = valid_hog_features\n",
    "X_test = test_hog_features\n",
    "\n",
    "# Prepare target vectors (labels) for train and validation sets\n",
    "y_train = train_generator.labels\n",
    "y_valid = valid_generator.labels\n",
    "\n",
    "# Perform least squares classification\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "y_pred_valid = model.predict(X_valid)\n",
    "\n",
    "# Evaluate the model (you can use appropriate metrics depending on your task)\n",
    "# For example, you can use mean squared error for regression tasks or accuracy for classification tasks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
