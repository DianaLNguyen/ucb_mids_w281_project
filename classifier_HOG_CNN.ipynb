{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e372cf81",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae4f2ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.8.8)\n",
      "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
      "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.22.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib scikit-image\n",
    "!pip install scikeras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from skimage import io\n",
    "from skimage import filters\n",
    "from skimage import exposure\n",
    "from skimage import color\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dda746",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422ab76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>suit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/train/ace of clubs/001.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/train/ace of clubs/002.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/train/ace of clubs/003.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/train/ace of clubs/004.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/train/ace of clubs/005.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filepaths   suit\n",
       "0  Dataset/train/ace of clubs/001.jpg  clubs\n",
       "1  Dataset/train/ace of clubs/002.jpg  clubs\n",
       "2  Dataset/train/ace of clubs/003.jpg  clubs\n",
       "3  Dataset/train/ace of clubs/004.jpg  clubs\n",
       "4  Dataset/train/ace of clubs/005.jpg  clubs"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the image paths and labels from the DataFrame\n",
    "df = pd.read_csv('Dataset/cards.csv')\n",
    "\n",
    "# For column names that contain space, replace the space with an underscore\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "\n",
    "# Add suits column\n",
    "df['suit'] = df['labels'].str.split().str[-1]\n",
    "\n",
    "# Remove rows with jokers\n",
    "df = df[~df['suit'].str.contains('joker', case=False)]\n",
    "\n",
    "# Remove unwanted columns\n",
    "df = df.drop(columns = ['data_set'])\n",
    "df = df.drop(columns = ['class_index'])\n",
    "df = df.drop(columns = ['labels'])\n",
    "df = df.drop(columns = ['card_type'])\n",
    "\n",
    "# Add folder name to the filepath\n",
    "df['filepaths'] = df['filepaths'].apply(lambda x: 'Dataset/' + x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf472b",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56cc11c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe into train and test sets, stratified by the 'suit' column\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['suit'], random_state=42)\n",
    "\n",
    "# Split train set into train and validation sets, stratified by the 'suit' column\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['suit'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01092bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set - Class Distribution:\n",
      "spades      0.269171\n",
      "hearts      0.246010\n",
      "diamonds    0.243675\n",
      "clubs       0.241144\n",
      "Name: suit, dtype: float64\n",
      "Validation Set - Class Distribution:\n",
      "spades      0.269261\n",
      "hearts      0.245914\n",
      "diamonds    0.243580\n",
      "clubs       0.241245\n",
      "Name: suit, dtype: float64\n",
      "Test Set - Class Distribution:\n",
      "spades      0.268991\n",
      "hearts      0.245953\n",
      "diamonds    0.244085\n",
      "clubs       0.240971\n",
      "Name: suit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution in the train, validation, and test sets\n",
    "train_class_distribution = train_df['suit'].value_counts(normalize=True)\n",
    "val_class_distribution = val_df['suit'].value_counts(normalize=True)\n",
    "test_class_distribution = test_df['suit'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Train Set - Class Distribution:\")\n",
    "print(train_class_distribution)\n",
    "\n",
    "print(\"Validation Set - Class Distribution:\")\n",
    "print(val_class_distribution)\n",
    "\n",
    "print(\"Test Set - Class Distribution:\")\n",
    "print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58840230",
   "metadata": {},
   "source": [
    "## Extract HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9a5c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    return image_gray\n",
    "\n",
    "\n",
    "def extract_hog_features(image_paths, labels):\n",
    "    featurelist = []\n",
    "    hog_example = None\n",
    "    label_list = []\n",
    "\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        img = load_img(image_path)\n",
    "        image_array = img_to_array(img)\n",
    "        gray_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
    "        fd, hog_image = hog(gray_image, \n",
    "                            pixels_per_cell=(8, 8),\n",
    "                            cells_per_block=(2, 2), \n",
    "                            orientations=4, \n",
    "                            visualize=True)\n",
    "\n",
    "        if i == 0:\n",
    "            hog_example = hog_image\n",
    "\n",
    "        featurelist.append(fd[np.newaxis, :])\n",
    "        label_list.append(labels[i])\n",
    "\n",
    "    features = np.vstack(featurelist)\n",
    "    labels = np.array(label_list)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c1b84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a portion of the train set\n",
    "train_fraction = 0.5 \n",
    "train_df_subset, _ = train_test_split(train_df, train_size=train_fraction, stratify=train_df['suit'], random_state=42)\n",
    "train_features, train_labels = extract_hog_features(train_df_subset['filepaths'].values, train_df_subset['suit'].values)\n",
    "\n",
    "# Map string labels to integer labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# One-hot encode the target labels\n",
    "num_classes = len(label_encoder.classes_)\n",
    "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea13ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a portion of the validation set\n",
    "val_fraction = 0.5 \n",
    "val_df_subset, _ = train_test_split(val_df, test_size=val_fraction, stratify=val_df['suit'], random_state=42)\n",
    "val_features, val_labels = extract_hog_features(val_df_subset['filepaths'].values, val_df_subset['suit'].values)\n",
    "\n",
    "# Map string labels to integer labels using LabelEncoder (same label_encoder as for the training set)\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "\n",
    "# One-hot encode the target labels for the validation set\n",
    "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "959c14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = extract_hog_features(test_df['filepaths'].values, test_df['suit'].values)\n",
    "# test_labels_encoded = label_encoder.transform(test_labels)\n",
    "# test_labels_onehot = to_categorical(test_labels, num_classes=num_classes)\n",
    "\n",
    "# test_fraction = 0.5 \n",
    "# test_df_subset, _ = train_test_split(test_df, test_size=test_fraction, stratify=test_df['suit'], random_state=42)\n",
    "# test_features, test_labels = extract_hog_features(test_df_subset['filepaths'].values, test_df_subset['suit'].values)\n",
    "\n",
    "# Map string labels to integer labels using LabelEncoder (same label_encoder as for the training set)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# One-hot encode the target labels for the test set\n",
    "test_labels_onehot = to_categorical(test_labels_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44eade",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b681154",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_features.shape[1],)))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b2d2a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 08:52:47.502387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:655] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-30 08:52:47.556758: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x5588b17194e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-30 08:52:47.556796: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2023-07-30 08:52:47.580321: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-30 08:52:47.622378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8902\n",
      "2023-07-30 08:52:47.798227: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 1s 4ms/step - loss: 1.3633 - accuracy: 0.3262 - val_loss: 1.2685 - val_accuracy: 0.4346\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 1.1934 - accuracy: 0.4831 - val_loss: 1.1546 - val_accuracy: 0.4984\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 1.0605 - accuracy: 0.5640 - val_loss: 1.0591 - val_accuracy: 0.5826\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.9053 - accuracy: 0.6637 - val_loss: 0.9772 - val_accuracy: 0.5888\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.7988 - accuracy: 0.7135 - val_loss: 1.0082 - val_accuracy: 0.5748\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.7493 - val_loss: 0.9457 - val_accuracy: 0.5950\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.8050 - val_loss: 0.9440 - val_accuracy: 0.6059\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.8373 - val_loss: 0.9327 - val_accuracy: 0.6168\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8443 - val_loss: 0.9244 - val_accuracy: 0.6106\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8840 - val_loss: 0.8806 - val_accuracy: 0.6495\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.9007 - val_loss: 0.9192 - val_accuracy: 0.6386\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8918 - val_loss: 0.8982 - val_accuracy: 0.6293\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9085 - val_loss: 0.8632 - val_accuracy: 0.6573\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.9486 - val_loss: 0.9223 - val_accuracy: 0.6153\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.9482 - val_loss: 0.9002 - val_accuracy: 0.6511\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.9607 - val_loss: 0.9277 - val_accuracy: 0.6340\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9669 - val_loss: 1.0939 - val_accuracy: 0.6028\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9689 - val_loss: 0.9276 - val_accuracy: 0.6542\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9821 - val_loss: 1.0671 - val_accuracy: 0.6340\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9747 - val_loss: 1.1364 - val_accuracy: 0.5935\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network model\n",
    "history = model.fit(train_features, train_labels_onehot,\n",
    "                    batch_size=32,\n",
    "                    epochs=20,\n",
    "                    validation_data=(val_features, val_labels_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "valid_predictions_probs = model.predict(valid_hog_features)\n",
    "valid_predictions = np.argmax(valid_predictions_probs, axis=1)\n",
    "\n",
    "# Calculate validation accuracy\n",
    "valid_accuracy = accuracy_score(valid_generator.labels, valid_predictions)\n",
    "print(\"Validation Accuracy:\", valid_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_probs = model.predict(test_hog_features)\n",
    "test_predictions = np.argmax(test_predictions_probs, axis=1)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = accuracy_score(test_generator.labels, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9ea0dc",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae4b67e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(val_labels_onehot, \u001b[43mval_predictions\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define the class labels\u001b[39;00m\n\u001b[1;32m      4\u001b[0m class_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspades\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhearts\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiamonds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclubs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(val_labels_onehot, val_predictions)\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = ['spades', 'hearts', 'diamonds', 'clubs']\n",
    "\n",
    "# Create the seaborn heatmap\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True, \n",
    "            fmt=\"d\", \n",
    "            cmap=\"Blues\", \n",
    "            xticklabels=class_labels, \n",
    "            yticklabels=class_labels)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"SVM - Confusion Matrix\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1344128",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454bf210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class names from the generator\n",
    "class_names = list(['spades', 'hearts', 'diamonds', 'clubs'])\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification report for validation set\n",
    "valid_report = classification_report(val_labels, valid_predictions, target_names=class_names)\n",
    "print(\"Validation Classification Report:\\n\", valid_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc5b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification report for test set\n",
    "test_report = classification_report(test_labels, test_predictions, target_names=class_names)\n",
    "print(\"Test Classification Report:\\n\", test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a336baa",
   "metadata": {},
   "source": [
    "## PCA Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on the HOG features.\n",
    "pca = PCA()\n",
    "hog_features_pca = pca.fit_transform(train_features)\n",
    "\n",
    "# Cumulative explained variance.\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Plot fifty principal components\n",
    "num_components = min(2000, len(cumulative_explained_variance))\n",
    "components_range = np.arange(1, num_components + 1, 100)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(components_range, cumulative_explained_variance[components_range - 1], marker='o')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA - Cumulative Explained Variance')\n",
    "plt.xticks(components_range, fontsize=6)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
