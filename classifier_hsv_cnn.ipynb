{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "048c5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import color\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.measure import regionprops, find_contours\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from utils import *\n",
    "from feature_util import *\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8cda539c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>suit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/train/ace of clubs/001.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/train/ace of clubs/002.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/train/ace of clubs/003.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/train/ace of clubs/004.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/train/ace of clubs/005.jpg</td>\n",
       "      <td>clubs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filepaths   suit\n",
       "0  Dataset/train/ace of clubs/001.jpg  clubs\n",
       "1  Dataset/train/ace of clubs/002.jpg  clubs\n",
       "2  Dataset/train/ace of clubs/003.jpg  clubs\n",
       "3  Dataset/train/ace of clubs/004.jpg  clubs\n",
       "4  Dataset/train/ace of clubs/005.jpg  clubs"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the image paths and labels from the DataFrame\n",
    "df = pd.read_csv('Dataset/cards.csv')\n",
    "\n",
    "# For column names that contain space, replace the space with an underscore\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "\n",
    "# Add suits column\n",
    "df['suit'] = df['labels'].str.split().str[-1]\n",
    "\n",
    "# Remove rows with jokers\n",
    "df = df[~df['suit'].str.contains('joker', case=False)]\n",
    "\n",
    "# Remove unwanted columns\n",
    "df = df.drop(columns = ['data_set'])\n",
    "df = df.drop(columns = ['class_index'])\n",
    "df = df.drop(columns = ['labels'])\n",
    "df = df.drop(columns = ['card_type'])\n",
    "\n",
    "# Add folder name to the filepath\n",
    "df['filepaths'] = df['filepaths'].apply(lambda x: 'Dataset/' + x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2fabeb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set - Class Distribution:\n",
      "spades      0.269171\n",
      "hearts      0.246010\n",
      "diamonds    0.243675\n",
      "clubs       0.241144\n",
      "Name: suit, dtype: float64\n",
      "Validation Set - Class Distribution:\n",
      "spades      0.269261\n",
      "hearts      0.245914\n",
      "diamonds    0.243580\n",
      "clubs       0.241245\n",
      "Name: suit, dtype: float64\n",
      "Test Set - Class Distribution:\n",
      "spades      0.268991\n",
      "hearts      0.245953\n",
      "diamonds    0.244085\n",
      "clubs       0.240971\n",
      "Name: suit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split dataframe into train and test sets, stratified by the 'suit' column\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['suit'], random_state=42)\n",
    "\n",
    "# Split train set into train and validation sets, stratified by the 'suit' column\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['suit'], random_state=42)\n",
    "\n",
    "# Check class distribution in the train, validation, and test sets\n",
    "train_class_distribution = train_df['suit'].value_counts(normalize=True)\n",
    "val_class_distribution = val_df['suit'].value_counts(normalize=True)\n",
    "test_class_distribution = test_df['suit'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Train Set - Class Distribution:\")\n",
    "print(train_class_distribution)\n",
    "\n",
    "print(\"Validation Set - Class Distribution:\")\n",
    "print(val_class_distribution)\n",
    "\n",
    "print(\"Test Set - Class Distribution:\")\n",
    "print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b360a9b",
   "metadata": {},
   "source": [
    "## Augment Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2dd1b9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5138 validated image filenames belonging to 4 classes.\n",
      "Found 1285 validated image filenames belonging to 4 classes.\n",
      "Found 1606 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize data generator class\n",
    "\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    #rescale = 1/255.0,   #Want 0 to 255 values for the color histogram\n",
    "    rotation_range= 45,\n",
    "    zoom_range= 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range= 0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "test_data_generator = ImageDataGenerator() #rescale = 1/255.0) #want 0 to 255 values for the color histogram\n",
    "\n",
    "# Create data generators for train, validation, and test\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "valid_generator = test_data_generator.flow_from_dataframe( #change this to use test_data_generator since don't want to augment the valid images\n",
    "    dataframe = val_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe( #change this to use test_data_generator since don't want to augment the valid images\n",
    "    dataframe = test_df,\n",
    "    x_col = 'filepaths',\n",
    "    y_col = 'suit',\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b23cf",
   "metadata": {},
   "source": [
    "## CNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e5af2a",
   "metadata": {},
   "source": [
    "### Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43437342",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hist_hue(image):\n",
    "    \n",
    "    # Convert the image from RGB to HSV\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Calculate histograms for each channel\n",
    "    hist_hue = cv2.calcHist([image_hsv], [0], None , [255], [0, 256]).astype(np.uint8)\n",
    "    \n",
    "    #normalize \n",
    "    hist_hue_normalized = (hist_hue - np.min(hist_hue)) / (np.max(hist_hue)  - np.min(hist_hue) )\n",
    "\n",
    "    # Scale the normalized histogram to have values between 0 and 255\n",
    "    hist_hue_scaled = (hist_hue_normalized * 255).astype(np.uint8)\n",
    "    \n",
    "    return hist_hue_scaled\n",
    "\n",
    "# Function to compute hsv features for a batch of images\n",
    "def extract_hue_features_from_generator(data_generator):\n",
    "    hsv_features = []\n",
    "    labels = []\n",
    "    num_batches = len(data_generator)\n",
    "    \n",
    "    for _ in range(num_batches):\n",
    "        batch_images, class_labels = data_generator.next()  # Get the next batch of augmented images (ignoring the labels)\n",
    "        \n",
    "        # Compute hue features for each image in the batch\n",
    "        for image, label in zip(batch_images,class_labels):\n",
    "            hue_feature = hist_hue(image).flatten()  \n",
    "            hsv_features.append(hue_feature)\n",
    "            label = list(label)\n",
    "            labels.append(label)\n",
    "            \n",
    "    return np.array(hsv_features),labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "824f9848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-ce5ec460fdbb>:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  hist_saturation_normalized = hist_saturation / np.sum(hist_saturation)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_saturation_features, train_labels = extract_saturation_features_from_generator(train_generator)\n",
    "valid_saturation_features, valid_labels = extract_saturation_features_from_generator(valid_generator)\n",
    "test_saturation_features, test_labels = extract_saturation_features_from_generator(test_generator)\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "valid_labels = np.array(valid_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a1177551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn using the train saturation features\n",
    "num_classes = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_saturation_features.shape[1],)))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d87774f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "322/322 [==============================] - 2s 3ms/step - loss: 20.3553 - accuracy: 0.3293 - val_loss: 17.1465 - val_accuracy: 0.3292\n",
      "Epoch 2/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 11.9293 - accuracy: 0.3548 - val_loss: 12.5533 - val_accuracy: 0.3595\n",
      "Epoch 3/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 8.2101 - accuracy: 0.3608 - val_loss: 8.7146 - val_accuracy: 0.3580\n",
      "Epoch 4/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 6.0296 - accuracy: 0.3760 - val_loss: 7.1284 - val_accuracy: 0.3541\n",
      "Epoch 5/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 4.6792 - accuracy: 0.3852 - val_loss: 5.9104 - val_accuracy: 0.3541\n",
      "Epoch 6/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 3.8693 - accuracy: 0.3889 - val_loss: 5.2068 - val_accuracy: 0.3502\n",
      "Epoch 7/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 3.2693 - accuracy: 0.3972 - val_loss: 4.6242 - val_accuracy: 0.3634\n",
      "Epoch 8/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 2.8723 - accuracy: 0.4132 - val_loss: 4.2853 - val_accuracy: 0.3572\n",
      "Epoch 9/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 2.5337 - accuracy: 0.4095 - val_loss: 3.9492 - val_accuracy: 0.3611\n",
      "Epoch 10/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 2.3079 - accuracy: 0.4200 - val_loss: 3.6825 - val_accuracy: 0.3634\n",
      "Epoch 11/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 2.1221 - accuracy: 0.4221 - val_loss: 3.4985 - val_accuracy: 0.3658\n",
      "Epoch 12/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 1.9480 - accuracy: 0.4216 - val_loss: 3.1850 - val_accuracy: 0.3681\n",
      "Epoch 13/20\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.7346 - accuracy: 0.4389 - val_loss: 3.1298 - val_accuracy: 0.3720\n",
      "Epoch 14/20\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1.6760 - accuracy: 0.4346 - val_loss: 2.9639 - val_accuracy: 0.3626\n",
      "Epoch 15/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 1.5127 - accuracy: 0.4646 - val_loss: 2.8648 - val_accuracy: 0.3642\n",
      "Epoch 16/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 1.5141 - accuracy: 0.4547 - val_loss: 2.7592 - val_accuracy: 0.3611\n",
      "Epoch 17/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 1.4051 - accuracy: 0.4644 - val_loss: 2.6621 - val_accuracy: 0.3626\n",
      "Epoch 18/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 1.3430 - accuracy: 0.4646 - val_loss: 2.5426 - val_accuracy: 0.3564\n",
      "Epoch 19/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 1.2967 - accuracy: 0.4724 - val_loss: 2.5402 - val_accuracy: 0.3611\n",
      "Epoch 20/20\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 1.2346 - accuracy: 0.4856 - val_loss: 2.5469 - val_accuracy: 0.3611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa76e523bb0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the CNN model\n",
    "model.fit(train_saturation_features, train_labels,\n",
    "                    batch_size=16,\n",
    "                    epochs=20,\n",
    "                    validation_data=(valid_saturation_features, valid_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "17282d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_valid = model.predict(valid_saturation_features)\n",
    "predict_classes_valid =np.argmax(predict_valid,axis=1)\n",
    "\n",
    "classes_valid_labels = np.argmax(valid_labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "381d9a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.21      0.24       310\n",
      "           1       0.35      0.23      0.28       313\n",
      "           2       0.37      0.47      0.41       316\n",
      "           3       0.39      0.52      0.45       346\n",
      "\n",
      "    accuracy                           0.36      1285\n",
      "   macro avg       0.35      0.36      0.34      1285\n",
      "weighted avg       0.35      0.36      0.35      1285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the class names from the generator (assuming it has the 'class_indices' attribute)\n",
    "class_indices = train_generator.class_indices\n",
    "class_names = list(class_indices.keys())\n",
    "\n",
    "# Calculate classification report for validation set\n",
    "valid_report = classification_report(classes_valid_labels, predict_classes_valid)\n",
    "print(\"Validation Classification Report:\\n\", valid_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "195adf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fa7701ecee0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion = confusion_matrix(classes_valid_labels,predict_classes_valid)\n",
    "disp = ConfusionMatrixDisplay(confusion,display_labels = class_names)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a458d49a",
   "metadata": {},
   "source": [
    "### Hog and Hue feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "73e6638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_hue_features_from_generator(data_generator):\n",
    "    hog_features = []\n",
    "    hsv_features = []\n",
    "    labels = []\n",
    "    num_batches = len(data_generator)\n",
    "    \n",
    "    for _ in range(num_batches):\n",
    "        batch_images, class_labels = data_generator.next()  # Get the next batch of augmented images (ignoring the labels)\n",
    "        \n",
    "        # Compute hue features for each image in the batch\n",
    "        for image, label in zip(batch_images,class_labels):\n",
    "           \n",
    "            hue_feature = hist_hue(image).flatten()  \n",
    "            hsv_features.append(hue_feature)\n",
    "            label = list(label)\n",
    "            labels.append(label)\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) \n",
    "            gray_image = gray_image.astype(np.uint8)\n",
    "            hog_feature = hog(gray_image, orientations = 8, pixels_per_cell=(16, 16), cells_per_block=(4, 4))\n",
    "            hog_features.append(hog_feature)\n",
    "            \n",
    "    hog_hue_feature = np.hstack((hog_features, hsv_features)) #hog_features \n",
    "            \n",
    "    return np.array(hog_hue_feature), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5c9236c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-83-bfb9af43eecb>:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  hist_hue_normalized = (hist_hue - np.min(hist_hue)) / (np.max(hist_hue)  - np.min(hist_hue) )\n"
     ]
    }
   ],
   "source": [
    "train_hog_hue_features, train_labels = extract_hog_hue_features_from_generator(train_generator)\n",
    "valid_hog_hue_features, valid_labels = extract_hog_hue_features_from_generator(valid_generator)\n",
    "test_hog_hue_features, test_labels = extract_hog_hue_features_from_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0f3f41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_hog_hue_features.shape[1],)))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb376d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "322/322 [==============================] - 8s 21ms/step - loss: 2.2438 - accuracy: 0.3447 - val_loss: 1.6479 - val_accuracy: 0.3268\n",
      "Epoch 2/20\n",
      "322/322 [==============================] - 7s 21ms/step - loss: 1.4025 - accuracy: 0.4017 - val_loss: 1.3840 - val_accuracy: 0.3844\n",
      "Epoch 3/20\n",
      "322/322 [==============================] - 27s 85ms/step - loss: 1.2437 - accuracy: 0.4379 - val_loss: 1.3701 - val_accuracy: 0.3735\n",
      "Epoch 4/20\n",
      "322/322 [==============================] - 8s 24ms/step - loss: 1.1625 - accuracy: 0.4657 - val_loss: 1.3763 - val_accuracy: 0.3767\n",
      "Epoch 5/20\n",
      "322/322 [==============================] - 6s 19ms/step - loss: 1.1175 - accuracy: 0.4895 - val_loss: 1.3517 - val_accuracy: 0.3852\n",
      "Epoch 6/20\n",
      "322/322 [==============================] - 6s 18ms/step - loss: 1.0830 - accuracy: 0.5033 - val_loss: 1.3609 - val_accuracy: 0.3883\n",
      "Epoch 7/20\n",
      "322/322 [==============================] - 6s 19ms/step - loss: 1.0406 - accuracy: 0.5265 - val_loss: 1.3944 - val_accuracy: 0.3891\n",
      "Epoch 8/20\n",
      "322/322 [==============================] - 8s 23ms/step - loss: 0.9960 - accuracy: 0.5463 - val_loss: 1.4152 - val_accuracy: 0.3868\n",
      "Epoch 9/20\n",
      "322/322 [==============================] - 10s 32ms/step - loss: 0.9632 - accuracy: 0.5685 - val_loss: 1.4618 - val_accuracy: 0.3852\n",
      "Epoch 10/20\n",
      "322/322 [==============================] - 11s 35ms/step - loss: 0.9265 - accuracy: 0.5804 - val_loss: 1.4864 - val_accuracy: 0.3961\n",
      "Epoch 11/20\n",
      "322/322 [==============================] - 10s 31ms/step - loss: 0.8990 - accuracy: 0.6028 - val_loss: 1.5212 - val_accuracy: 0.3790\n",
      "Epoch 12/20\n",
      "322/322 [==============================] - 8s 26ms/step - loss: 0.8527 - accuracy: 0.6156 - val_loss: 1.6159 - val_accuracy: 0.3899\n",
      "Epoch 13/20\n",
      "322/322 [==============================] - 7s 23ms/step - loss: 0.8234 - accuracy: 0.6302 - val_loss: 1.6380 - val_accuracy: 0.3821\n",
      "Epoch 14/20\n",
      "322/322 [==============================] - 7s 21ms/step - loss: 0.8020 - accuracy: 0.6429 - val_loss: 1.6654 - val_accuracy: 0.3860\n",
      "Epoch 15/20\n",
      "322/322 [==============================] - 6s 20ms/step - loss: 0.7784 - accuracy: 0.6528 - val_loss: 1.8192 - val_accuracy: 0.3907\n",
      "Epoch 16/20\n",
      "322/322 [==============================] - 7s 22ms/step - loss: 0.7524 - accuracy: 0.6724 - val_loss: 1.7816 - val_accuracy: 0.4086\n",
      "Epoch 17/20\n",
      "322/322 [==============================] - 9s 28ms/step - loss: 0.7123 - accuracy: 0.6830 - val_loss: 1.7561 - val_accuracy: 0.4039\n",
      "Epoch 18/20\n",
      "322/322 [==============================] - 16s 51ms/step - loss: 0.6810 - accuracy: 0.6937 - val_loss: 1.8938 - val_accuracy: 0.3883\n",
      "Epoch 19/20\n",
      "322/322 [==============================] - 10s 32ms/step - loss: 0.6605 - accuracy: 0.7106 - val_loss: 1.8289 - val_accuracy: 0.3961\n",
      "Epoch 20/20\n",
      "322/322 [==============================] - 7s 22ms/step - loss: 0.6404 - accuracy: 0.7258 - val_loss: 1.9772 - val_accuracy: 0.3953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa76ee4ea00>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the CNN model\n",
    "model.fit(train_hog_hue_features, train_labels,\n",
    "                    batch_size=16,\n",
    "                    epochs=20,\n",
    "                    validation_data=(valid_hog_hue_features, valid_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1fda998d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_valid = model.predict(valid_hog_hue_features)\n",
    "predict_classes_valid =np.argmax(predict_valid,axis=1)\n",
    "\n",
    "classes_valid_labels = np.argmax(valid_labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2511b16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.21      0.26       310\n",
      "           1       0.36      0.31      0.33       313\n",
      "           2       0.42      0.44      0.43       316\n",
      "           3       0.41      0.60      0.49       346\n",
      "\n",
      "    accuracy                           0.40      1285\n",
      "   macro avg       0.39      0.39      0.38      1285\n",
      "weighted avg       0.39      0.40      0.38      1285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the class names from the generator (assuming it has the 'class_indices' attribute)\n",
    "class_indices = train_generator.class_indices\n",
    "class_names = list(class_indices.keys())\n",
    "\n",
    "# Calculate classification report for validation set\n",
    "valid_report = classification_report(classes_valid_labels, predict_classes_valid)\n",
    "print(\"Validation Classification Report:\\n\", valid_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
