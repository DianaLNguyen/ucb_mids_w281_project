{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db328c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install opencv-python\n",
    "#!pip3 install scikit-image\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage import convolve, binary_fill_holes\n",
    "from scipy.stats import mode\n",
    "\n",
    "from skimage import io, exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import canny\n",
    "from skimage.transform import rotate, hough_line, hough_line_peaks, resize\n",
    "from skimage.filters import threshold_otsu, sobel, gaussian, threshold_local\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b4490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from csv file\n",
    "\n",
    "path = pd.read_csv('Dataset/cards.csv')\n",
    "path_df = pd.DataFrame(path)\n",
    "# For column names that contain space, replace the space with an underscore\n",
    "path_df.columns = [c.replace(' ', '_') for c in path_df.columns]\n",
    "path_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60422b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df['suit'] = path_df['labels'].str.split().str[-1]\n",
    "print(path_df['suit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with jokers\n",
    "path_df = path_df[~path_df['suit'].str.contains('joker', case=False)]\n",
    "card_suits = path_df['suit'].unique()\n",
    "print(card_suits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d03283",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36009a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = path_df.drop(columns = ['data_set'])\n",
    "path_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f65292",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df['filepaths'] = path_df['filepaths'].apply(lambda x: 'DatasetPreProcessed/' + x)\n",
    "path_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "suit_class_mapping = {\n",
    "    'spades': 0,\n",
    "    'hearts': 1,\n",
    "    'diamonds': 2,\n",
    "    'clubs': 3\n",
    "}\n",
    "\n",
    "# Add a new column 'class_index' based on the suit labels\n",
    "path_df['suits_class_index'] = path_df['suit'].map(suit_class_mapping)\n",
    "path_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1bec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe into train and test sets\n",
    "train_df, test_df = train_test_split(path_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split train set into train and validation sets\n",
    "test_df, val_df = train_test_split(train_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e34d22",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = [224, 224]\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size + [3]))\n",
    "\n",
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e733871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't want to train model because it is already trained.\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d92e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_layer = Flatten()(base_model.output)\n",
    "prediction  = Dense(4, activation='softmax')(flatten_layer)\n",
    "model = Model(inputs=base_model.input, outputs=prediction)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d144a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = ImageDataGenerator(rescale = 1. /255,\n",
    "                                             shear_range=0.2,\n",
    "                                             zoom_range=0.2,\n",
    "                                             horizontal_flip=True)\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale=1. /255)\n",
    "\n",
    "\n",
    "training_set = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col='filepaths',\n",
    "    y_col='suit',\n",
    "    target_size=(224,224), \n",
    "    batch_size=8, \n",
    "    class_mode='categorical')\n",
    "\n",
    "val_set = test_data_generator.flow_from_dataframe(\n",
    "    dataframe = val_df,\n",
    "    x_col='filepaths',\n",
    "    y_col='suit',\n",
    "    target_size=(224,224), \n",
    "    batch_size=8, \n",
    "    class_mode='categorical')\n",
    "\n",
    "test_set = test_data_generator.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col='filepaths',\n",
    "    y_col='suit',\n",
    "    target_size=(224,224), \n",
    "    batch_size=8, \n",
    "    class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(training_set, \n",
    "                   validation_data=val_set, \n",
    "                   epochs=10,\n",
    "                   steps_per_epoch=len(training_set),\n",
    "                   validation_steps=len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot accuracy\n",
    "plt.plot(result.history['accuracy'], label='train_acc')\n",
    "plt.plot(result.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdd8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Loss\n",
    "plt.plot(result.history['loss'], label='train_loss')\n",
    "plt.plot(result.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfee134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "evaluation = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Loss:\", evaluation[0])\n",
    "print(\"Accuracy:\", evaluation[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1733ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions on the test set\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "\n",
    "# Convert the predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "print(predicted_labels)\n",
    "\n",
    "#Print the predicted labels\n",
    "# print(predicted_labels[1])\n",
    "# print(len(predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth labels for the test set\n",
    "true_labels = test_set.labels\n",
    "print(true_labels)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
